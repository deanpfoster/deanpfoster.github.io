<html>
<header>
<title>  Statistics 540: Sorting</title>
</header>
<body>

<p>

<center><h1>  Statistics 540: Sorting</h1></center>


<h2>Announcement</h2>

<ul>
  <li> HW issues?
</ul>

<H2>Sorting and complexity</h2>
<ul>
  <li> Easy scheme: shuffle and sort (do with cards)
       <ul>
	 <li> Complexity: exponential random time infinite worst case time
       </ul>
  <li> Bubble sort
       <ul>
	 <li> n<sup>2</sup> worst case time
	 <li> n<sup>2</sup> average case time
       </ul>
  <li> Selection sort
       <ul>
	 <li> n<sup>2</sup> worst case time
	 <li> n<sup>2</sup> average case time
       </ul>
  <Li> Quick sort (an ACM algorithm of the century)
       <p>
       <Ul>
	 <li> best case: n log(n)
	 <li> worst cast: n<sup>2</sup>
	 <li> Which is more accurate?
	 <li> average: n log(n) also! (Provable ONLY if you actually randomize)
       </ul>
  <li> Merge sort
       <p>
       <ul>
	 <li> best case: n log(n)
	 <li> worst cast: n log(n)
	 <li> But SLOWER than quick sort?  Now we are into empirical checking
       </ul>
  <li> Provable lower bound
       <ul>
	 <li> Each "if" statement can divide the class of all permutations into two bins
	 <li> There are n! bins to start with
	 <li> Thus it takes log(n!) yes-no questions to identify what the starting position is.
	 <li> So at least n log(n) if-then-else statements, plus other statements
       </ul>
  <li> Hash sort with merge sort in each bin
       <p>
       <ul>
	 <li> best expected case: O(n)
	 <li> Yikes! better than the lower bound?
	 <li> Notice a "hash" into n cells is the same as log(n) yes-no decisions
	 <li> worst case n log(n)
       </ul>
  <li> Which to use? (see perl <a href="sort.pl">code</a>)
</ul>


<hr>  
<em>
<p align=right>
<!-- hhmts start -->
Last modified: Tue Oct 30 08:26:14 2001
<!-- hhmts end -->
</em>
</body>

</html>

