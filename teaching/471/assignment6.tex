\documentclass[12pt]{extarticle}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage[usenames]{color}\definecolor{mypurple}{rgb}{.6,.0,.5}\newcommand{\note}[1]{\noindent{\textcolor{mypurple}{\{{\bf note:} \em #1\}}}}
\newcommand{\tech}[1]{\noindent{\textcolor{red}{\{{\bf technical note:} \em #1\}}}}

\renewcommand{\baselinestretch}{1.25}


\begin{document}
\setcounter{section}{5}

\section{Assignment 6: Calibrating forecasts}

(\href{assignment6.pdf}{pdf version}) 

\subsection{Regression}
This question will ask you to mimic what I did in class on Thursday
April 16th.  
\begin{enumerate}
\item Find a data set with at least 5 independent variables
  (i.e. X's).  (If you can't find anything more interesting you can
  use the baseball dataset or even the Boston housing data set.)
\item Fit a multiple regression to your data using linear terms.
\item Create the calibration plot and test if your model is calibrated.
\item Fit a model using interactions and test if it is calibrated.
\item Finally, download your data to our ``auction'' code and see if
  it finds any variables that you didn't find.  Test of the model
  generated by the auction code is calibrated.
\item Discussion: Did your method over fit the data?  How do you know?
\end{enumerate}

\subsection{Cross validation}

This question will have you frauduant loans.  The Y variable is then a
 ``OK'' or ``fraud'' response.  But if we treat these as zeros and
 ones we can do a regression on them.  We will also do the more
 sophicicated logistic regression.

\begin{itemize}
\item As usual, start by creating a linear fit, and testing
  calibration and then doing a fit which includes interactions and
  check it for calibration.
\item If you change the Y variable from the zero-one version to the
  ``yes'' or ``no'' version, JMP will do a logistic regression
  instead.  Save these predictions and create a calibration plot.  Did
  the logistic regression generate a better fit?
\item If you are using the JMP file, then 1/2 of the data will have
  been excluded.  Make predictions for the excluded data and see how
  well you predict them.  (I want an average error of prediction for
  the out of sample data.)  Does a calibrated forecast predict out of
  sample better than the uncalibrated forecast?
\item Now switch to using a classification loss. (I.e. you must guess
 either ``true'' or ``false.''  If you miss a ``true'' it costs you 50
dollars if you miss a false it costs you 1 dollar.).  Make a decision out
 of your probabilistic predictions.  How accurately does it predict?
  Now try using your uncalibrated forecasts.  How well do they fit?
  Explain what happens here.
\end{itemize}

\end{document}
