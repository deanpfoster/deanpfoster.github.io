<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>Stat 471 Fall 2009</TITLE>
<META NAME="description" CONTENT="Class 22">
<META NAME="keywords" CONTENT="class22">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="class22.css">
</HEAD>
<BODY TEXT = "#000000" bgcolor="#FFFFFF" alink="#CC0000" vlink="#0000CC" LANG="EN">
<FONT  color="0000000" FACE="Arial,Helvetica,Sans Serif">

<P>
<P CENTER>
<CENTER><H1> Stat 471 / 701 Fall 2009</H1></CENTER>
<P CENTER>
<CENTER> <H2>Time series continued.</H2></CENTER>
<B>Todays class.</B>
<DL >
<DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/bluepin.gif" ALT="*"><DD>Autocorrelation
<DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/bluepin.gif" ALT="*"><DD>The correlogram
<DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/bluepin.gif" ALT="*"><DD>Processes
  <DL >
    <DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/redpin.gif" ALT="*"><DD>A purely random process
    <DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/redpin.gif" ALT="*"><DD>A random walk
    <DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/redpin.gif" ALT="*"><DD>Moving average process (MA)
    <DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/redpin.gif" ALT="*"><DD>Autoregressive process (AR)
    <DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/redpin.gif" ALT="*"><DD>Mixed ARMA models
    <DT><IMG WIDTH=20 HEIGHT=20 SRC="http://www-stat.wharton.upenn.edu/~waterman/icons/redpin.gif" ALT="*"><DD>ARIMA models
<P>
 </DL> 
 </DL>
<P>
<B>What we are doing: models for univariate time series - modeling the
residuals.</B>
<P>
Back to the correlogram
<P>
A key <B>assumption</B>: second order stationarity
<P>
<P> <IMG WIDTH=432 HEIGHT=20 ALIGN=BOTTOM ALT="displaymath93" SRC="img1.gif"  > <P>
<P>
In English: the mean is constant and the autocorrelation depends only on 
the lag.
<P>
<H2>Types of processes: the building blocks.</H2>
<P>
<B>A purely random process.</B>
<P>
A discrete time process is <EM>purely random</EM> if it consists of a sequence
of random variables  <IMG WIDTH=35 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline95" SRC="img2.gif"  >  which are mutually independent and 
identically distributed.
<P>
The autocorrelation function is
<P>
<P> <IMG WIDTH=361 HEIGHT=48 ALIGN=BOTTOM ALT="displaymath97" SRC="img3.gif"  > <P>
<P>
Colloquially known as ``White noise''.
<P>
<HR>
<P>
<B>Random Walk</B>
<P>
Let  <IMG WIDTH=35 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline95" SRC="img2.gif"  >  be purely random process, mean  <IMG WIDTH=11 HEIGHT=18 ALIGN=MIDDLE ALT="tex2html_wrap_inline101" SRC="img4.gif"  >  and variance  <IMG WIDTH=17 HEIGHT=33 ALIGN=MIDDLE ALT="tex2html_wrap_inline103" SRC="img5.gif"  > .
Then  <IMG WIDTH=38 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline105" SRC="img6.gif"  >  is a <EM>random walk</EM> if
<P> <IMG WIDTH=315 HEIGHT=16 ALIGN=BOTTOM ALT="displaymath107" SRC="img7.gif"  > <P>
<P>
If  <IMG WIDTH=67 HEIGHT=27 ALIGN=MIDDLE ALT="tex2html_wrap_inline109" SRC="img8.gif"  >  then  <IMG WIDTH=106 HEIGHT=33 ALIGN=MIDDLE ALT="tex2html_wrap_inline111" SRC="img9.gif"  > .
<P>
Can show that  <IMG WIDTH=100 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline113" SRC="img10.gif"  >  and  <IMG WIDTH=125 HEIGHT=32 ALIGN=MIDDLE ALT="tex2html_wrap_inline115" SRC="img11.gif"  > . Mean and variance
change with <I>t</I>, therefore non-stationary.
<P>
<B>But</B> differences, ie  <IMG WIDTH=126 HEIGHT=25 ALIGN=MIDDLE ALT="tex2html_wrap_inline119" SRC="img12.gif"  >  are purely random and
therefore stationary.
<P>
Example: the market.
<P>
Price on day t = price on day (t - 1 ) + noise.
<P>
<HR>
<P>
<B>Moving average process</B>
<P>
Say  <IMG WIDTH=35 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline95" SRC="img2.gif"  >  is purely random, mean 0 variance  <IMG WIDTH=17 HEIGHT=33 ALIGN=MIDDLE ALT="tex2html_wrap_inline103" SRC="img5.gif"  > . Then  <IMG WIDTH=38 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline105" SRC="img6.gif"  >  
is a moving average process of order q ( MA(q) ) if
<P> <IMG WIDTH=390 HEIGHT=20 ALIGN=BOTTOM ALT="displaymath127" SRC="img13.gif"  > <P>
<P>
In English a weighted sum of the Z's.
<P>
One can show that the autocorrelation function is
<P>
<P> <IMG WIDTH=432 HEIGHT=66 ALIGN=BOTTOM ALT="displaymath129" SRC="img14.gif"  > <P>
<P>
Important point is that it drops off for <I>k</I> &gt; <I>q</I>.
<P>
Special case (scale so  <IMG WIDTH=51 HEIGHT=29 ALIGN=MIDDLE ALT="tex2html_wrap_inline133" SRC="img15.gif"  > ), an MA(1) process
<P>
<P> <IMG WIDTH=389 HEIGHT=66 ALIGN=BOTTOM ALT="displaymath135" SRC="img16.gif"  > <P>
<P>
<HR>
<P>
<B>Autoregressive process.</B>
<P>
 <IMG WIDTH=35 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline95" SRC="img2.gif"  >  is purely random mean 0, variance  <IMG WIDTH=17 HEIGHT=33 ALIGN=MIDDLE ALT="tex2html_wrap_inline103" SRC="img5.gif"  > .
Then a process is autoregressive of order <I>p</I> if
<P> <IMG WIDTH=388 HEIGHT=19 ALIGN=BOTTOM ALT="displaymath141" SRC="img17.gif"  > <P>
Like a regression, but  <IMG WIDTH=21 HEIGHT=27 ALIGN=MIDDLE ALT="tex2html_wrap_inline143" SRC="img18.gif"  >  is regressed on previous X's.
The present depends on the past plus some error.
<P>
Special case AR(1) process.
<P> <IMG WIDTH=319 HEIGHT=16 ALIGN=BOTTOM ALT="displaymath145" SRC="img19.gif"  > <P>.
<P>
It turns out that the AR(1) process is second order stationary if
 <IMG WIDTH=54 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline147" SRC="img20.gif"  > .
<P>
The autocorrelation function is
<P>
<P> <IMG WIDTH=289 HEIGHT=22 ALIGN=BOTTOM ALT="displaymath149" SRC="img21.gif"  > <P>
<P>
a geometric decline - so look for this in the correlogram.
<P>
The Durbin Watson test is a test under the assumption that the process
is AR(1), whether or not  <IMG WIDTH=68 HEIGHT=30 ALIGN=MIDDLE ALT="tex2html_wrap_inline151" SRC="img22.gif"  > .
<P>
<HR>
<P>
<B>Mixed ARMA models.</B>
<P>
A combination of an MA and an AR model.
<P>
<P> <IMG WIDTH=484 HEIGHT=20 ALIGN=BOTTOM ALT="displaymath153" SRC="img23.gif"  > <P>
<P>
Important because a stationary process may be more simply described
through a mixed ARMA model, than a pure MA or AR process.
<P>
<HR>
<P>
<B>ARIMA models</B>
<P>
For a non-stationary process, (for example a series with trend) we may apply
differencing at the start to achieve stationarity on the differenced series.
Then apply ARMA models to this differences series.
<P>
To get back from the stationary model to a model for the original data you 
have to undo the differencing, that is to sum (or <B>I</B>ntegrate). Hence
AutoRegressive, Integrated Moving Average model. (ARIMA).
<P>
</P></P><BR> <HR>
<P><ADDRESS>
<I>Richard Waterman <BR>
</ADDRESS>
</FONT>
</BODY>
</HTML>
