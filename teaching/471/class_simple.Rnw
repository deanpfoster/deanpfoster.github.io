\documentclass{article}
\usepackage{hyperref}
\begin{document}

\title{Class: Taylor}
\maketitle
(\href{class_doglegs.pdf}{pdf version})

\section*{Story time: Willingham, the Cog Psyc}
 
\begin{itemize}
\item Willingham: Professor of cognitive psychology at Harvard
\item \href{http://www.amazon.com/Why-Dont-Students-Like-School/dp/0470279303/ref=sr_1_1?ie=UTF8&s=books&qid=1263385854&sr=1-1}{Why students don't like school}
\item We know lots about psychology now
\item amazingly little about education:
\begin{itemize}
\item Perry preschool project is still a state of the art education experiment
\item There are few other good controlled experiments
\end{itemize}
\item But we can use what we know about psychology to inform education
\item That is the aproach of this book
\item For example: He pushes stories
\begin{itemize}
\item People relate to humans with special hardware in their brain
(cards vs lier), so try to tell stories 
\item People pay attention at start of class--new stuff is always
interesting.  So no need for it to have a connected theme
\item People like closure--so each class should provide a conclusion
\end{itemize}
\end{itemize}


\section*{Admistrivia}

\begin{itemize}
\item homework / ``cases'' project and a final 
\item Wave grading and interactions
  \begin{itemize}
  \item Make a wave and invite me and Sivan to it
  \item This will be our way of communicating between the three of us
  \end{itemize}
\item Books
  \begin{itemize}
  \item  Introductory Statistics with R by Peter Dalgaard, 2nd edition, ISBN 978-0-387-79053-4, Springer 2008.
  \item  Linear Models with R by Julian J. Faraway, ISBN 1-58488-425-8, Chapman \& Hall/CRC Press 2005. 
  \end{itemize}
\item Software R
  \begin{itemize}
  \item Allow other software--but recommend R
  \item Its free, available on OS X/Linux/windows.
  \item It is what production level statisticians use
  \item I'll give a short introduction to R after class on Monday
  \end{itemize}
\end{itemize}

\section*{Todays Topic: Simple linear regression}

\section*{Review of the standard linear model}

The standard linear regression model is:
\begin{displaymath}
Y_i = \alpha + \beta x_i + \epsilon_i \quad \epsilon_i \sim_{iid}
N(0,\sigma^2)
\end{displaymath}
You will see this equation written in almost any research paper which
uses data.  The names are often changed, but it is there somewhere.
For example, it is basically equation 2.17 in Berndt of the reading.
The entire chapter is designed to motivate that one equation.

Let's break it down into pieces.
\begin{itemize}
\item The fit:
\begin{displaymath}
Y_i = \underbrace{\alpha + \beta x_i}_{\hbox{the fit}} + \epsilon_i \quad \epsilon_i \sim_{iid}
N(0,\sigma^2)
\end{displaymath}
the most fun part is ``the fit''.  It describes the relationship
between $x$ and $Y$.  This version describes a linear relationship. 

\item Residuals / errors:
\begin{displaymath}
Y_i = \alpha + \beta x_i + \underbrace{\epsilon_i \quad \epsilon_i
\sim_{iid} N(0,\sigma^2)}_{\hbox{The residuals}}
\end{displaymath}
The residuals (aka errors) themselves.  Describing them,
looking at them, investigating them is the primary activity of a
statistician.  It is all about error!
\begin{itemize}
\item The ``i.d.'':  The i.i.d. part can be broken into two pieces, ``i.''
and ``i.d.''  The easier is the identically distributed.  It means
each error looks like any other error.

\item The ``i.'': The first ``i'' in IID is for independence.  We will
spend an entire class on this piece.  It is the most important
assumption in the entire model.

\item the ``N'': Means normal.  Look at a q-q plot to check it.  It is
easy to check (hence we cover it in intro classes).  We won't discuss
it here since I assume you already know how to check it.

\item Style: iid = i.i.d. = IID = I.I.D. = independent and identically
distributed.  It is often even left off entirely since it is always
assumed. 
\end{itemize}

\item $Y$ is upper case, $x$ is lower case: Recall from probability that
random variables are often writtten as upper case letters.  This is
why $Y$ is written as an upper case--it is random.  The $x$ are
thought of as inputs, and hence not random.

\item $i$ is the row index.  We might even say how many rows we have
by the cryptic addition to the equation:
\begin{displaymath}
(i = 1,\ldots,n) \quad
Y_i = \alpha + \beta x_i + \epsilon_i \quad \epsilon_i \sim_{iid}
N(0,\sigma^2)
\end{displaymath}
\end{itemize}
\section{Is linear good enough?}

Taylor (\href{http://en.wikipedia.org/wiki/Brook_Taylor}{wiki}) tells
us that ``everything'' can be approximated by a linear equation.  So
if there is a true relationship between $Y$ and $x$ that is
non-linear, then we could say 
\begin{displaymath}
E(Y|x) = f(x)
\end{displaymath}
(This is yet another cryptic for of our main equation.  It could be
written as $Y = f(x) + \epsilon$ to make it look more like our
previous equation.)  So Taylor's theorem says that
\begin{displaymath}
E(Y|x) \approx \alpha + \beta x
\end{displaymath}
and even tells us what $\alpha$ and $\beta$ are.  

\section{Practice}

First get the data.  For me, I use the command line, just like your grandfather used: 
\begin{verbatim}
 wget http://www-stat.wharton.upenn.edu/~waterman/fsw/datasets/txt/Cleaning.txt
\end{verbatim}
You of course have this new fangled deviced called a mouse--so use it!  Now start R.
First read in the file:
<<step1,eval=FALSE>>=
read.table("Cleaning.txt")
@ 
%
Oops, that generates too much output, and doesn't put it anywhere.
So let's assign all this mess to a data frame.
<<step2,eval=FALSE>>=
clean = read.table("Cleaning.txt")
@ 
%
Just look at what we have by typing ``clean'' again.  Oops--we have
the first row with the names of the variables in it.  So let's try again: 
<<step3,eval=TRUE>>=
clean = read.table("Cleaning.txt",header=TRUE)
@ 
%
Checking with ``clean'' shows we only have numbers.  How happy can
you get?!? Now for the fun part, let's run a regression.
<<step4>>=
lm(clean$RoomsClean ~ clean$NumberOfCrews)
@ 
%
Kinda a different world view than JMP.  It just gives the minimal
amount of output possible.  So to see a bit more, try
<<step5>>=
summary(lm(clean$RoomsClean ~ clean$NumberOfCrews))
@ 
%
That should look very similar to other tables you have seen.  But what
of pictures?  Well, let's do a plot:
<<step5,fig=TRUE>>=
plot(lm(clean$RoomsClean ~ clean$NumberOfCrews))
@ 
\end{document}
