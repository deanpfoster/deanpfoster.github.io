\documentclass[14pt]{extarticle}
\usepackage{hyperref}
\SweaveOpts{prefix.string=.figures/chapter5}
\usepackage{wrapfig}
\usepackage{graphicx}
\begin{document}
\title{Chapter 5 teaching notes}
\author{Dean P Foster}
\maketitle


\section*{Administrivia}

\begin{itemize}
\item No class monday
\item I'll hold a review of homework only.  No exam questions
allowed. (Fairness issues and to discurage people from coming.) So it
will probably be short.
\end{itemize}



\section*{Story time}

\begin{itemize}
\item Paradox: Two numbers between -one and one written in two envelops.
\item   Nice strategy, go with the bigger interval.  Works more than 1/2 the
 time for all distributions.  Equilvant to, ``pick in the direction of
 1/2.''
\item Can be defeated.
\item Fix the defeat by randomizing the 1/2
 point.  Always works!
\item Now, do it for a whole real line.
\item Want a compress the whole line to
 -1,1.  Nice trick, $tan^{-1}()$
\item Creates Cauchy.
\item It has high probability of generating
 large numbers.
\end{itemize}

\section*{Simulation tricks}

Random variables generated by bernulli trials:
\begin{itemize}
\item Can just simulate the bernulli trials:
\begin{itemize}
\item Do $n$ trials and count success for binomial
\item Count tosses until first success for geometric
\item Count tosses until kth success for negative binomial
\end{itemize}
\item But for $p \approx 0$ this can be slow
\begin{itemize}
\item Say $p = 1/million$, how long until first success?
\item About a million tosses
\end{itemize}
\item Trick: use a continuous distribution to approximate the answer 
\item For binomial, use a normal
\item For geometric, use a exponential
\item For negative binomial, use a sum of ``fast geometrics''
\end{itemize}

\section*{Exponential distribution}
\begin{itemize}
\item Limit of geometric distribution
\item Generated by $ - \frac{1/\lambda} \log(1 - U)$.
\item Where did this come from?
\begin{itemize}
\item Theorem: For $X$ with continuous CDF $F$, the $F(X)$ is a
uniform.
\item Proof: $P(U < u) = P(U < F(x)) = P(F(X) < F(x)) = P(X < x) =
F(X) = u$.
\end{itemize}
\item The CDF for an exponential is $F(x) = 1 - e^{- \lambda x}$
\item $x = - 1/\lambda \log(1 - F(x))$
\end{itemize}

see
\href{http://en.wikipedia.org/wiki/Inverse_transform_sampling}{wiki on
inverse sampling}


\section*{Cool properties of exponential}
\begin{itemize}
\item Model for waiting times
\item How long do you wait until next person arrives in a line? Exponential.
\item Related questions:
\begin{itemize}
\item How long until 10 more people arrive? (Sum of 10 exponentials,
called a gamma distribution.)
\item How may arrive in 20 miutes? (How many exponentials are needed
to generate at least a 20 minute total wait?  Called Poisson.)
\end{itemize}
\end{itemize}

\section*{Normal}
\begin{itemize}
\item Most important distribution in probability
\item Good model for lost of stuff
\item  approximately normal examples
\begin{itemize}
\item Binomial 
\item negative binomial
\item Poisson
\item Gamma
\item Everything but exponential!  (Not really, also Cauchy)
\end{itemize}
\item It would be a good world if it were simple, it isn't.
\end{itemize}

\section*{How to simulate a normal?}
\begin{itemize}
\item Use an exponential!
\item Flip coin to generate sign.
\item Draw an exponential.
\item Subsample by ratio of normal to exponential
\item Some math can make this as tight as possible
\item \href{http://en.wikipedia.org/wiki/Rejection\_sampling}{Wiki on rejectin sampling}
\item Some math:
\begin{eqnarray*}
-x^2/2 & \le & -|x| + 1/2 \quad \left(\hbox{Draw the picture}\right)\\
-x^2/2 & \le & -x + 1/2  \quad \left(\hbox{for positive $x$}\right)\\
0 & \le & (x - 1)^2/2 \\
f_{exp}(x) & = & e^{-|x|}/2 \\
f_{norm}(x) & = & k e^{-x^2/2} \\
k \frac{f_{norm}(x)}{f_{exp}(x)} & = & e^{-(|x|-1)^2/2} \\
\{U < k \frac{f_{norm}(x)}{f_{exp}(x)}\} & = & \{-\log(U) > (|x|-1)^2/2)\}
\end{eqnarray*}
\end{itemize}


\begin{figure}

<<rejection,fig=TRUE,include=FALSE,echo=FALSE>>=

laplace <- function(x) exp(-abs(x))/2
k_norm  <- function(x) exp(-x^2/2)*exp(-.5)/2
x <- seq(-5,5,.001)
plot(x,lapply(x,laplace),type="l",lwd=3,ylab="density",col="red")
polygon(x,lapply(x,laplace),col="yellow",pch=FALSE,border=FALSE)
lines(x,lapply(x,laplace),type="l",lwd=3,col="red")
polygon(x,lapply(x,k_norm),col="green",pch=FALSE,border=FALSE)
lines(x,lapply(x,k_norm),type="l",lwd=3,col="blue")

@ 
\includegraphics{.figures/chapter5-rejection}
\caption{It is easy to sample from an exponential distribution (use
$-\ln(U)$).  If we attach a random sign, we get a Laplace distribution
shown in yellow.  If we then subsample with probability $e^{-(|x| -
1)^2}$ we will get the distribution shown in green--which is a normal
distribution.  Ignoring signs, in psudo code this looks like\protect\\\protect\\
{\tt
\hspace*{2in}repeat \protect\\
\hspace*{2.5in}$X = - \log(U)$ \protect\\
\hspace*{2in}until $-2 * \log(U) < (X - 1.0)^2$
}}
\end{figure}


\section*{Conclusions}
\begin{itemize}
\item Read the chapter, do the homework.
\item There are whole books about special distributions
\item The ones we disussed are useful in all fields
\item But there are many specialized to particular fields:
\begin{itemize}
\item Physics has Boltsman ? Maxwell and Rayleigh distributions
\item Finanace has a log-normal
\item Statistics chi-squared (and many others)
\item Survival analysis (when will you die) has hazard models
\end{itemize}
\end{itemize}

\end{document}
