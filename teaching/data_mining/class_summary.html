<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html> <head>
<title>Statistical Data mining: Summary and open problems</title>
</head>

<body>
<p align=right>
<!-- hhmts start -->
Last modified: Thu Dec  8 14:53:17 EST 2005
<!-- hhmts end -->
by <a href="http://gosset.wharton.upenn.edu/~foster/">Dean Foster</a>
<p>

<h2>Admistrivia</h2>
<ul>
   <li>  Homework 5 is on line.  Due Dec 19th.
   <li> None are supposed to be killers.  So if you are having
problems, send me an email.  I probably phrase the question wrong or
thought it was much easier than it really is.  So I'll rewrite it in
either case.
   <li> As usual questions on homework?  Not everyone is done.  
</ul>


<h1>Summary and open problems</h1>

<h2>Review: What we have learned this semester</h2>
<ul>
  <li> High dim. data takes its own way of thinking
  <li> Get to study old things all over again
    <ul>
	<li> For example: how would design of experiments look in 1 Million
            dimensions?
    </ul>
  <li> Minor philosophy issues go away: p-values vs. posterior are
irrevelant at bonferroni scale
  <li> Good statistical reasoning still the foundation
</ul>

<h2>Why am I interested in data mining?</h2>
<ul>
   <li> I trained in AI before it did statistics
     <ul>
     <li> They solved noise by fuzzy logic
     <li> Tried to cover ALL exceptions in definitions
     <li> Generally an abasimal failure
     <li> I flunked out since I kept saying: "Do statistics"
     <li> Its payback time!
     </ul>
   <li> Big picture: Old school AI with actual answers
   <li> Small picture: game of "Go"
   <li> What keeps me doing it:
      <ul>
      <li> Relevant theory!
      <li> exciting applications!
      </ul>
   <li> Get me drunk enough, and I'll even tell you about the
singilarity.  In fact, you won't be able to stop me from telling you
about it!
</ul>


<h2>So you want to do a PhD in data mining?</h2>


<h3>Why: Easy Advances are possible</h3>
<ul>
   <li> Since it is a new area, a little theory and a little
application goes a long way
   <li> Become an expert with respect.  (Everyone thinks they know as
much stochastic processes as they want to know already.)
</ul>

<h3>We have some of the best people working on it</h3>
<ul>
   <li> Adi does the information theory and Boosting
   <li> Andreas does high dimenstion visualation
   <li> Abba does applications
   <li> Bob, Lyle and I have a research group with several on going
projects.
</ul>

<h3>Applications</h3>
<ul>
  <li> Marketing
  <li> Biology
    <ul>
    <li> Genes
    <li> Proteins
    <li> Function between these
    </ul>
  <li> Doctors / medicine
  <li> Astronomy
  <li> Weather
  <li> Linguistics
    <ul>
    <li> text mining
    <li> search (all of google)
    <li> text understanding
    </ul>
  <li> vison
</ul>

<h3>Theory</h3>

<ul>
  <li> Compromizes between classification and forecasting
  <li> Finding new features
  <li> Functional analysis stuff
  <li> Bayes nets
  <li> trees
  <li> Pick any two above and combine
</ul>

<h3>Connection to machine learning</h3>

<ul>
  <li> Recursive structure: Ontological leaps
  <li> Different kind of models: connection between many things
   <li> Very different approaches: same goals
   <li> Advantage of doing data mining is you can publish 3 times:
      <ul>
      <li> in ML conference (turn around 3 months)
      <li> in domain area (turn around 1 year)
      <li> in statistics (turn around 3 years)
      </ul>
   <li> We have a strong group on campus (raided Bell Labs a few years
back when they were busy folding.)
</ul>

 <hr>
<address>dean@foster.net</address>
</body> </html>
