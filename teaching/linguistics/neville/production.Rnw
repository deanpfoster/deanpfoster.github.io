\documentclass[14pt]{extarticle}

\SweaveOpts{prefix.string=.figures/dean}


\begin{document}

This is ``going for gold'' version of analysing the SAD data.  So
no-exploration of the data--just trying to do the right thing.  
<<readData,echo=FALSE>>=

#load("data.rda")
sad.df <- read.table("small.txt",header=TRUE)
names(sad.df)[1:10]
Y  <- sad.df$isSpeech
Xs <- sad.df[,3:dim(sad.df)[2]]
p  <- dim(Xs)[2]
domains <- sad.df$domain
@

\section*{Leaving out a domain}

Our general approach will be to fit on all but one of the domains and
predict that last domain.  So first let's write something that will
determine our accuracy on this left out domain.  Note, we all systems
that look at unlabelled out-of-sample data.  I don't think any code
I'll be writing soon uses this feature--but it seems right headed to
allow it.

<<leftOutDomains,echo=FALSE>>=

compute_out_of_sample <- function(Y, Xs, domains, fitter)
{
    domain.list <- levels(domains)
    errors <- list()
    errors$in.sample  <- rep(NA,length(domain.list))
    errors$out <- rep(NA,length(domain.list))
    names(errors$in.sample) <- domain.list
    names(errors$out) <- domain.list
    leave.out.fits <- rep(NA,dim(Xs)[1])
    data <- data.frame(Xs)

    for(i in domain.list)
    {
        i.indexes <- (domains == i)
        data$Y <- Y
        data$Y[i.indexes] <- NA
        fits <- fitter(data, domains, i)
        best.guess <- (fits > .5)
        errors$in.sample[i] <- mean(best.guess[i.indexes] != Y[i.indexes])
        errors$out[i] <- mean(best.guess[-i.indexes] != Y[-i.indexes])
    }
    return(errors)
}

@

\subsection*{Checking it works}

Let's check that the leave one out actually works as advertised.  Here
is a trivially fitter method:

<<lmFitter>>=

lm_fitter <- function(data, domains, left.out)
{
  model <- lm(Y ~ . , data=data)
  fitted.values <- model$fitted.values
  return(fitted.values)
}

@ 

Checking the code works:

<<lmFitterCheck>>=

  errors <- compute_out_of_sample(Y, Xs, domains, lm_fitter)
  mean(errors$out)

@ 

And as a plot, we can see the massive over fitting.

<<outVSin,fig=TRUE,include=FALSE,echo=FALSE>>=

plot(errors$in.sample,errors$out,
     xlab="using all data",ylab="using other domains",
     col=c("red","blue")[1+ (errors$in.sample > errors$out)],pch=16, log = "xy")
abline(0,1) # 45 degree line

@

In the following graph, I have color coded the ones where the true
forecasts are better in blue, and all the rest in red.  Basically the
true forecasts are garbage compared to the insample forecasts.

\includegraphics[width=6in]{.figures/dean-outVSin}

\section*{Finding a robust model}

Let's try to find a robust model which will perform well reguardless
of which domains it actually is trained on.  To do that, we want to
find variables which have about the same coefficient reguardless of
which domains it is used on. 

<<StreamingTukey>>=

start.time <- proc.time()[1]
stop.time <- start.time + 10  # should be 10 seconds

residuals <- Y - mean(Y)
variables.to.try <- list()
variables.found <- list()
for(i in 1:length(Xs))
  {
    variables.to.try[[length(variables.to.try)+1]] = Xs[,i]
    names(variables.to.try)[length(variables.to.try)] = colnames(Xs)[i]
  }
model <- rep(1,length(residuals))
omega <- .5
wealth <- omega
location <- 1 # same number tried since we have the constant in already
while((proc.time()[1] < stop.time) && (location <= length(variables.to.try)))
    {
      next.variable <- variables.to.try[[location]]
      next.name <- names(variables.to.try)[location]
      orthogonal.variable <- lm(next.variable ~ model)$residuals
      betas <- summary(lm(residuals ~ orthogonal.variable:sad.df$domain-1))$coefficients[,1]
      results <- t.test(betas)
      bid <- wealth / (number.tried + 1)
      wealth <- wealth - bid
      number.tried <- number.tried + 1
      location <- location + 1
      if(results$p.value < bid)
        {
          model <- cbind(model, i)
          residuals <- lm(Y ~ model)$residuals
          cat("added ",next.names," with a t-stat of ", statistics[2]," and p-value of ", p.value, " < ", bid,".\n")
          wealth = wealth + omega 
          variables.found <- push(next.variable)
          for(j in variables.found)
            {
              variables.to.try[[length(variables.to.try)+1]] <- j * next.variable
              names(variables.to.try)[length(variables.to.try)] <- paste(names(j)," * ",next.name)
            }
        }
      else
        {
          cat("giving up on ",next.name,". t-stat was ", results$statistic, ".\n")
        }
    }


@
Which now includes only $ \Sexpr{dim(model)[2]-1} $ variables out of all
of them (namely $ \Sexpr{length(names(sad.df))} $).  Let's see how well
it does on the out-of-sample game.

Here is the picture that we want to compare to our previous results.
It isn't spactiuarilly better.  But still it is somewhat better.

<<domainAdaption,fig=TRUE,include=FALSE>>=

model.all.lm <- lm(sad.df$isSpeech ~ model)
model.all.best.guess <- (model.all.lm$fitted.values > .5)
model.all.errors <- (model.all.best.guess != sad.df$isSpeech)
model.all.x <- summary(lm(model.all.errors ~ sad.df$domain - 1))$coef[,1]

plot(model.all.x,model.all.x,xlab="using all data on robust model",ylab="using other
domains (and few variables)",col=c("red","blue")[1+ (model.all.x > model.all.x)],pch=16)
abline(0,1)


@

\includegraphics[width=6in]{.figures/dean-domainAdaption}




\newpage
\section*{assuming IID}
The following assumes IID (which is evil and wrong):

<<StreamingIID>>=

residuals <- Y - mean(Y)
variables.to.try <- Xs
model <- rep(1,length(residuals))
omega <- .5
wealth <- omega
number.tried <- 1 # for the constant term
for(i in variables.to.try[1:30])
    {
        orthogonal.variable <- lm(i ~ model)$residuals
        statistics <- summary(lm(residuals ~ orthogonal.variable))$coefficients[2,]
        p.value <- statistics[4]
        bid <- wealth / (number.tried + 1)
        wealth <- wealth - bid
        number.tried <- number.tried + 1
        if(p.value < bid)
            {
                model <- cbind(model, i)
                residuals <- lm(Y ~ model)$residuals
                cat("added ",names(i)," with a t-stat of ", round(statistics[2],2)," and p-value of ", signif(p.value,2), " < ", signif(bid,2),".\n")
                wealth = wealth + omega 
            }
    }


@
The model includes $ \Sexpr{dim(model)[2]} $ variables out of only $30$
that were tried.


\end{document}
