\documentclass[14pt]{extarticle}
\renewcommand{\baselinestretch}{1.2}
\usepackage{hyperref}
\begin{document}
\SweaveOpts{prefix.string=.figures/notes}

\title{Class: POS (chapter 5)}
\maketitle

\section*{Admistrivia}

\begin{itemize}
\item 
\end{itemize}

\section*{Story: Colorless green ideas sleep furiously.}

\subsection*{Noam Chomsky}
\begin{itemize}
\item Studied at U Penn
\item Works at MIT
\item Writes more than anyone else in the world!  
\begin{itemize}
\item Most cited author (alive) (Only 7th when he dies: Marx, Lenin,
Shakespere, Aristotal, God, Plato, Freud)
\end{itemize}
\item Built complex model of language
\item Most famous for 5 words: Colorless green ideas sleep furiously.
\end{itemize}

\subsection*{Mitch Marcus}
\begin{itemize}
\item Studied at MIT
\item Works at Penn
\item Almost never writes papers--but still was president of
Lingustics society?  How?  Good students! And a few good papers.
\item Uses simple statistical models (HMM say)
\item Most famous for 1 million words: Penn Tree Bank.
\end{itemize}


\section*{POS: open vs closed}

Key distinction: open class vs. closed class.
\begin{itemize}
\item Open class is ``infinite''
\item Closed class is ``finite''
\item More accurately, we have good lists for closed class
\item For example, there are only three articles (a form of
 determiner) in English: ``a'', ``an'' and ``the''.
\item There are an infinite number of proper nouns.
\end{itemize}

\subsection*{Examples of closed classes}

\begin{description}
\item[prepositions]  prepositions: on, under
\item[determiners] a, an, the, this, that
\item[pronouns] he, she, I, others
\item[conjunctions] and, or
\item[auxiliary verbs] may, can
\item[particles] up, down
\item[numerals] one, two, yikes, not to infinity?
\end{description}

\subsection*{Open classes}

\begin{description}
\item[noun]
\item[verbs]
\item[adjetives]
\item[adverbs] 
\end{description}

\subsection*{Irregular verbs: open or closed class}

\begin{itemize}
\item There are only about 50 irregular verbs.
\item So is it a closed class?  Kinda: but not really.  Maybe it
 depends on what you are doing with them.
\item Certainly, if you are learning English, it is a closed class
 worth memorizing.
\item Basically they are historic artifacts from a previous grammar.
  So they once were regular.  Only a few verbs out of an infinite set
 made it past the great vowel shift.
\end{itemize}

\subsection*{The difference between open and closed}

Closed class words are sometimes called {\em function} words.
(I.e. think operators in mathematics)
\begin{itemize}
\item Hence have ideoscratic usages (think of all the ways we use
``$+$'' in mathematics)
\item Can have hand coded rules since they are finite
\end{itemize}

Open class words are often called {\em content} words.  There are
 words that you know and will only hear / read about 100 times in your
 entire life.  Hard to list all of them, but they follow regular rules
typically. 

\subsection*{But what are the 85 classes of English words?}

\begin{itemize}
\item Like the normal table--it appears on the front cover of the
book.
\item Also ``grep'' help is there
\item So we are now at the ``+/- two SD'' level into linguistics.
Just kidding!
\end{itemize}

\section*{Taggers}

General methods of taggers:
\begin{itemize}
\item Rule based: i.e. hand coding
\item HMM based: i.e. a probabilistic model
\item Transformation based tagging: i.e. ``y-hat on the RHS'' and regression
\end{itemize}

\section*{Rule based}

\subsection*{Algorithm:}
\begin{itemize}
\item Give multiple tags from a dictionary
\item Use rules to eliminate stupid tag sequences
\end{itemize}

\subsection*{Generally Hand coded}
\begin{itemize}
\item Rules are written by hand.
\item Most (90\%) types are unique -- so dictionary gets them right
\item Almosts most tokens (40\%) are ambiguous -- so dictionary is just a guess
\item Huh? rare words are unique, common words have many meanings / usages.
\item Rules have good data on either side and hence work well
\end{itemize}

\subsection*{Can be statistical}
Probabilistic rule systems exist


\section*{HMM based}
\begin{itemize}
\item POS are ``hidden'' states
\item Each token is drawn conditionally on POS
\item POS follows Markov chain
\item Goal: find the most likely POS sequence for a sentence
\item Method: Viterbi / forward-backwards / EM
\item Example:
\begin{itemize}
\item Secretariat is expected to RACE tomorrow.
\item Secretariat/NNP is/BEZ expected/TO to/VB RACE/NN* tomorrow/NR.
\item ``Race'' is most often a noun.  So this is a first-pass tagging.
\item But, $P(NN|TO) = .0047$ where as $P(VB|TO) = .83$
\item So the Markov rules adjust the final probability of 99.9\% in
favor of VB.  A better tag here.
\end{itemize}
\item We'll talk about HMM's next time
\end{itemize}

\section*{Transformation based (aka statistics)}

\begin{itemize}
\item First pass: label POS via dictionary look up.  Pick best one.
\item Second pass: use neighboring POS to improve current POS
\item Repeat with better neighbors
\item Regression on ``Y-hats'' from neighbors
\item Can be done using statistics
\item Note: Lisha (one of our PhD students) did a bit of
 y-on-the-right-hand-side a few years ago
\end{itemize}

\section*{Stanford POS tagger}
\begin{itemize}
\item Uses 4 on each side
\item A log-linear model (i.e. logistic / multiple logistic)
\item see
(\href{http://nlp.stanford.edu/~manning/papers/tagging.pdf}{Toutanova, Klein, Manning, Yoram})
for details.
\item Acts kinda like HMM combined with transformation
\end{itemize}


\section*{Evaluation of performance}

Wow, that tagger is 97.25\% accurate!
\begin{itemize}
\item Is this good or bad?
\item Yea, its good!  Sounds pretty impressive.  But then, an naive
model gets 85\% accurate.  Just look the word up in a dictionary.
\item Boo its bad!  People got 97\% a while ago--so this isn't much
better than 10 years ago.
\item What is ground truth:
\begin{itemize}
\item What humans tag things as (Note: expensive.  Humans can do 3000
words per hour.  Or about a penny a word.  It takes one month of
training--so not so easy to use Mechnical Turk.)
\item The Stanford log-linear POS tagger (15,000 words per second.  Or
about a penny per million.  97\% accurate.)
\end{itemize}
\end{itemize}



\end{document}
